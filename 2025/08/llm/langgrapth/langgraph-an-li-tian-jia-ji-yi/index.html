<!DOCTYPE html>
<html lang="zh-Hans">
  <head>
    

    
<script>!function(){var e=window.matchMedia&&window.matchMedia("(prefers-color-scheme: dark)").matches,t=localStorage.getItem("use-color-scheme")||"auto";("dark"===t||e&&"light"!==t)&&document.documentElement.classList.toggle("dark",!0)}()</script>
    

<meta charset="utf-8" >

<title>LangGraph 案例：添加记忆</title>
<meta name="keywords" content="LangGraph 案例：添加记忆, 花日の博客">
<meta name="description" content="聊天机器人现在可以使用工具来回答用户的问题，但它无法记住之前交互的上下文。这限制了它进行连贯、多轮对话的能力。
LangGraph 通过持久化检查点checkpointer解决了这个问题。如果您在编译图时提供，并thread_id在调用图时">
<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta property="og:title" content="LangGraph 案例：添加记忆">
<meta property="og:description" content="聊天机器人现在可以使用工具来回答用户的问题，但它无法记住之前交互的上下文。这限制了它进行连贯、多轮对话的能力。
LangGraph 通过持久化检查点checkpointer解决了这个问题。如果您在编译图时提供，并thread_id在调用图时">

<link rel="shortcut icon" href="/images/huari.ico">
<link rel="stylesheet" href="/style/main.css">

  <meta name="generator" content="Hexo 7.3.0"></head>
  <body>
    <div id="app" class="main">

<div class="site-header-container">
  <div class="site-header">
    <div class="left">
      <a href="http://hua-ri.cn">
        <img class="avatar" src="/images/huari-image.png" alt="logo" width="32px" height="32px">
      </a>
      <a href="http://hua-ri.cn">
        <h1 class="site-title">花日の博客</h1>
      </a>
    </div>
    <div class="right">
        <i class="icon menu-switch icon-menu-outline" ></i>
    </div>
  </div>
</div>

<div class="menu-container" style="height: 0;opacity: 0;">
<nav class="menu-list">
  
    
      <a href="/" class="menu purple-link">
        首页
      </a>
    
  
    
      <a href="/tags" class="menu purple-link">
        标签
      </a>
    
  
    
      <a href="/categories" class="menu purple-link">
        分类
      </a>
    
  
    
      <a href="/archives" class="menu purple-link">
        归档
      </a>
    
  
    
      <a href="/about" class="menu purple-link">
        关于
      </a>
    
  
</nav>
</div>



  <div class="content-container">
    <div class="post-detail">
      
      <h2 class="post-title">LangGraph 案例：添加记忆</h2>
      <div class="post-info post-detail-info">
        <span><i class="icon icon-calendar-outline"></i> 2025-08-20</span>
        
          <span>
          <i class="icon icon-pricetags-outline"></i>
            
              <a href="/tags/llm/">
              llm
                
                  ，
                
              </a>
            
              <a href="/tags/langgraph/">
              langgraph
                
              </a>
            
          </span>
        
      </div>
      <div class="post-content-wrapper">
        <div class="post-content">
          <p>聊天机器人现在可以<a href="https://hua-ri.cn/2025/08/llm/langgrapth/langgraph-an-li-ji-qi-ren-tian-jia-gong-ju/">使用工具</a>来回答用户的问题，但它无法记住之前交互的上下文。这限制了它进行连贯、多轮对话的能力。</p>
<p>LangGraph 通过<strong>持久化检查点</strong><code>checkpointer</code>解决了这个问题。如果您在编译图时提供，并<code>thread_id</code>在调用图时提供 ，LangGraph 会在每一步之后自动保存状态。当您再次使用相同的 调用图时<code>thread_id</code>，图会加载其已保存的状态，从而允许聊天机器人从上次中断的地方继续执行。</p>
<p>我们稍后会看到，<strong>检查点</strong>比简单的聊天记忆功能强大<em>得多</em>——它允许您随时保存和恢复复杂的状态，以进行错误恢复、人机交互、时间旅行交互等等。但首先，让我们添加检查点来实现多轮对话。</p>
<blockquote>
<p>本教程以<a href="https://hua-ri.cn/2025/08/llm/langgrapth/langgraph-an-li-ji-qi-ren-tian-jia-gong-ju/">添加工具</a>为基础。</p>
</blockquote>
<h1 id="创建MemorySaver检查点"><a href="#创建MemorySaver检查点" class="headerlink" title="创建MemorySaver检查点"></a>创建<code>MemorySaver</code>检查点</h1><p>创建<code>MemorySaver</code>检查点：</p>
<p><em>API</em> <em>参考：</em><a target="_blank" rel="noopener" href="https://langchain-ai.github.io/langgraph/reference/checkpoints/#langgraph.checkpoint.memory.InMemorySaver">InMemorySaver</a></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">from langgraph.checkpoint.memory import InMemorySaver</span><br><span class="line"></span><br><span class="line">memory = InMemorySaver()</span><br></pre></td></tr></table></figure>

<p>这是内存检查点，这对于本教程来说很方便。但是，在生产应用程序中，您可能会将其更改为使用<code>SqliteSaver</code>或<code>PostgresSaver</code>连接数据库。</p>
<h1 id="编译图表"><a href="#编译图表" class="headerlink" title="编译图表"></a>编译图表</h1><p>使用提供的检查点编译图表，<code>State</code>当图表通过每个节点时，它将检查点：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">graph = graph_builder.<span class="built_in">compile</span>(checkpointer=memory)</span><br></pre></td></tr></table></figure>



<h1 id="与你的聊天机器人互动"><a href="#与你的聊天机器人互动" class="headerlink" title="与你的聊天机器人互动"></a>与你的聊天机器人互动</h1><p>现在您可以与您的机器人互动！</p>
<ol>
<li>选择一个线索作为本次对话的关键。</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">config = &#123;&quot;configurable&quot;: &#123;&quot;thread_id&quot;: &quot;1&quot;&#125;&#125;</span><br></pre></td></tr></table></figure>

<ol>
<li>呼叫您的聊天机器人：</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">user_input = <span class="string">&quot;Hi there! My name is Will.&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># The config is the **second positional argument** to stream() or invoke()!</span></span><br><span class="line">events = graph.stream(</span><br><span class="line">    &#123;<span class="string">&quot;messages&quot;</span>: [&#123;<span class="string">&quot;role&quot;</span>: <span class="string">&quot;user&quot;</span>, <span class="string">&quot;content&quot;</span>: user_input&#125;]&#125;,</span><br><span class="line">    config,</span><br><span class="line">    stream_mode=<span class="string">&quot;values&quot;</span>,</span><br><span class="line">)</span><br><span class="line"><span class="keyword">for</span> event <span class="keyword">in</span> events:</span><br><span class="line">    event[<span class="string">&quot;messages&quot;</span>][-<span class="number">1</span>].pretty_print()</span><br></pre></td></tr></table></figure>



<p>对话记录</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">================================ Human Message =================================</span><br><span class="line"></span><br><span class="line">Hi there! My name is Will.</span><br><span class="line">================================== Ai Message ==================================</span><br><span class="line"></span><br><span class="line">Hello, Will! Nice to meet you. How can I assist you today?</span><br></pre></td></tr></table></figure>



<h1 id="提出后续问题"><a href="#提出后续问题" class="headerlink" title="提出后续问题"></a>提出后续问题</h1><p>提出后续问题：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">user_input = <span class="string">&quot;Remember my name?&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># The config is the **second positional argument** to stream() or invoke()!</span></span><br><span class="line">events = graph.stream(</span><br><span class="line">    &#123;<span class="string">&quot;messages&quot;</span>: [&#123;<span class="string">&quot;role&quot;</span>: <span class="string">&quot;user&quot;</span>, <span class="string">&quot;content&quot;</span>: user_input&#125;]&#125;,</span><br><span class="line">    config,</span><br><span class="line">    stream_mode=<span class="string">&quot;values&quot;</span>,</span><br><span class="line">)</span><br><span class="line"><span class="keyword">for</span> event <span class="keyword">in</span> events:</span><br><span class="line">    event[<span class="string">&quot;messages&quot;</span>][-<span class="number">1</span>].pretty_print()</span><br></pre></td></tr></table></figure>



<p>对话记录：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">================================ Human Message =================================</span><br><span class="line"></span><br><span class="line">Remember my name?</span><br><span class="line">================================== Ai Message ==================================</span><br><span class="line"></span><br><span class="line">Of course! You mentioned your name is Will. Is there anything specific you&#x27;d like to know or discuss?</span><br></pre></td></tr></table></figure>

<p>变更下thread_id再次进行下测试：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">user_input = <span class="string">&quot;Remember my name?&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># The config is the **second positional argument** to stream() or invoke()!</span></span><br><span class="line">events = graph.stream(</span><br><span class="line">    &#123;<span class="string">&quot;messages&quot;</span>: [&#123;<span class="string">&quot;role&quot;</span>: <span class="string">&quot;user&quot;</span>, <span class="string">&quot;content&quot;</span>: user_input&#125;]&#125;,</span><br><span class="line">    &#123;<span class="string">&quot;configurable&quot;</span>: &#123;<span class="string">&quot;thread_id&quot;</span>: <span class="string">&quot;2&quot;</span>&#125;&#125;,</span><br><span class="line">    stream_mode=<span class="string">&quot;values&quot;</span>,</span><br><span class="line">)</span><br><span class="line"><span class="keyword">for</span> event <span class="keyword">in</span> events:</span><br><span class="line">    event[<span class="string">&quot;messages&quot;</span>][-<span class="number">1</span>].pretty_print()</span><br></pre></td></tr></table></figure>



<p>对话记录：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">================================ Human Message =================================</span><br><span class="line"></span><br><span class="line">Remember my name?</span><br><span class="line">================================== Ai Message ==================================</span><br><span class="line"></span><br><span class="line">Of course! How can I assist you today? If you have any questions or need information on a particular topic, feel free to ask.</span><br></pre></td></tr></table></figure>

<blockquote>
<p><strong>请注意</strong>，我们所做的<strong>唯一更改是修改了</strong><code>thread_id</code>的配置。</p>
</blockquote>
<h1 id="检查状态"><a href="#检查状态" class="headerlink" title="检查状态"></a>检查状态</h1><p>到目前为止，我们已经在两个不同的线程上创建了一些检查点。但是检查点包含哪些内容呢？要<code>state</code>随时检查给定配置的图表，请调用<code>get_state(config)</code>。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">snapshot = graph.get_state(config)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;snapshot1: &quot;</span>, snapshot)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;snapshot.next: &quot;</span>, snapshot.<span class="built_in">next</span>)</span><br><span class="line"></span><br><span class="line">snapshot = graph.get_state(&#123;<span class="string">&quot;configurable&quot;</span>: &#123;<span class="string">&quot;thread_id&quot;</span>: <span class="string">&quot;2&quot;</span>&#125;&#125;)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;snapshot2: &quot;</span>, snapshot)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;snapshot.next: &quot;</span>, snapshot.<span class="built_in">next</span>)</span><br></pre></td></tr></table></figure>

<p>结果：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">snapshot1:  StateSnapshot(values=&#123;<span class="string">&#x27;messages&#x27;</span>: [HumanMessage(content=<span class="string">&#x27;Hi there! My name is Will.&#x27;</span>, additional_kwargs=&#123;&#125;, response_metadata=&#123;&#125;, <span class="built_in">id</span>=<span class="string">&#x27;ecd9b10a-c211-401a-9445-adbc597c1044&#x27;</span>), AIMessage(content=<span class="string">&#x27;Hello, Will! Nice to meet you. How can I assist you today?&#x27;</span>, additional_kwargs=&#123;<span class="string">&#x27;refusal&#x27;</span>: <span class="literal">None</span>&#125;, response_metadata=&#123;<span class="string">&#x27;token_usage&#x27;</span>: &#123;<span class="string">&#x27;completion_tokens&#x27;</span>: <span class="number">17</span>, <span class="string">&#x27;prompt_tokens&#x27;</span>: <span class="number">1563</span>, <span class="string">&#x27;total_tokens&#x27;</span>: <span class="number">1580</span>, <span class="string">&#x27;completion_tokens_details&#x27;</span>: <span class="literal">None</span>, <span class="string">&#x27;prompt_tokens_details&#x27;</span>: <span class="literal">None</span>&#125;, <span class="string">&#x27;model_name&#x27;</span>: <span class="string">&#x27;qwen2.5:7b&#x27;</span>, <span class="string">&#x27;system_fingerprint&#x27;</span>: <span class="string">&#x27;fp_ollama&#x27;</span>, <span class="string">&#x27;id&#x27;</span>: <span class="string">&#x27;chatcmpl-52&#x27;</span>, <span class="string">&#x27;service_tier&#x27;</span>: <span class="literal">None</span>, <span class="string">&#x27;finish_reason&#x27;</span>: <span class="string">&#x27;stop&#x27;</span>, <span class="string">&#x27;logprobs&#x27;</span>: <span class="literal">None</span>&#125;, <span class="built_in">id</span>=<span class="string">&#x27;run--1c9c145c-6fa4-415f-92b6-47f84997466b-0&#x27;</span>, usage_metadata=&#123;<span class="string">&#x27;input_tokens&#x27;</span>: <span class="number">1563</span>, <span class="string">&#x27;output_tokens&#x27;</span>: <span class="number">17</span>, <span class="string">&#x27;total_tokens&#x27;</span>: <span class="number">1580</span>, <span class="string">&#x27;input_token_details&#x27;</span>: &#123;&#125;, <span class="string">&#x27;output_token_details&#x27;</span>: &#123;&#125;&#125;), HumanMessage(content=<span class="string">&#x27;Remember my name?&#x27;</span>, additional_kwargs=&#123;&#125;, response_metadata=&#123;&#125;, <span class="built_in">id</span>=<span class="string">&#x27;5b1c1d1f-7178-4326-81a0-0beb501521fc&#x27;</span>), AIMessage(content=<span class="string">&quot;Of course! You mentioned your name is Will. Is there anything specific you&#x27;d like to know or discuss?&quot;</span>, additional_kwargs=&#123;<span class="string">&#x27;refusal&#x27;</span>: <span class="literal">None</span>&#125;, response_metadata=&#123;<span class="string">&#x27;token_usage&#x27;</span>: &#123;<span class="string">&#x27;completion_tokens&#x27;</span>: <span class="number">23</span>, <span class="string">&#x27;prompt_tokens&#x27;</span>: <span class="number">1593</span>, <span class="string">&#x27;total_tokens&#x27;</span>: <span class="number">1616</span>, <span class="string">&#x27;completion_tokens_details&#x27;</span>: <span class="literal">None</span>, <span class="string">&#x27;prompt_tokens_details&#x27;</span>: <span class="literal">None</span>&#125;, <span class="string">&#x27;model_name&#x27;</span>: <span class="string">&#x27;qwen2.5:7b&#x27;</span>, <span class="string">&#x27;system_fingerprint&#x27;</span>: <span class="string">&#x27;fp_ollama&#x27;</span>, <span class="string">&#x27;id&#x27;</span>: <span class="string">&#x27;chatcmpl-599&#x27;</span>, <span class="string">&#x27;service_tier&#x27;</span>: <span class="literal">None</span>, <span class="string">&#x27;finish_reason&#x27;</span>: <span class="string">&#x27;stop&#x27;</span>, <span class="string">&#x27;logprobs&#x27;</span>: <span class="literal">None</span>&#125;, <span class="built_in">id</span>=<span class="string">&#x27;run--faa5caf2-81bb-4150-b5c9-c049c8ef30a4-0&#x27;</span>, usage_metadata=&#123;<span class="string">&#x27;input_tokens&#x27;</span>: <span class="number">1593</span>, <span class="string">&#x27;output_tokens&#x27;</span>: <span class="number">23</span>, <span class="string">&#x27;total_tokens&#x27;</span>: <span class="number">1616</span>, <span class="string">&#x27;input_token_details&#x27;</span>: &#123;&#125;, <span class="string">&#x27;output_token_details&#x27;</span>: &#123;&#125;&#125;)]&#125;, <span class="built_in">next</span>=(), config=&#123;<span class="string">&#x27;configurable&#x27;</span>: &#123;<span class="string">&#x27;thread_id&#x27;</span>: <span class="string">&#x27;1&#x27;</span>, <span class="string">&#x27;checkpoint_ns&#x27;</span>: <span class="string">&#x27;&#x27;</span>, <span class="string">&#x27;checkpoint_id&#x27;</span>: <span class="string">&#x27;1f07cbc5-e584-67b8-8004-70fd49b674a1&#x27;</span>&#125;&#125;, metadata=&#123;<span class="string">&#x27;source&#x27;</span>: <span class="string">&#x27;loop&#x27;</span>, <span class="string">&#x27;step&#x27;</span>: <span class="number">4</span>, <span class="string">&#x27;parents&#x27;</span>: &#123;&#125;&#125;, created_at=<span class="string">&#x27;2025-08-19T05:21:32.702483+00:00&#x27;</span>, parent_config=&#123;<span class="string">&#x27;configurable&#x27;</span>: &#123;<span class="string">&#x27;thread_id&#x27;</span>: <span class="string">&#x27;1&#x27;</span>, <span class="string">&#x27;checkpoint_ns&#x27;</span>: <span class="string">&#x27;&#x27;</span>, <span class="string">&#x27;checkpoint_id&#x27;</span>: <span class="string">&#x27;1f07cbc5-da23-6766-8003-fece86761aa4&#x27;</span>&#125;&#125;, tasks=(), interrupts=())</span><br><span class="line">snapshot.<span class="built_in">next</span>:  ()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">snapshot2:  StateSnapshot(values=&#123;<span class="string">&#x27;messages&#x27;</span>: [HumanMessage(content=<span class="string">&#x27;Remember my name?&#x27;</span>, additional_kwargs=&#123;&#125;, response_metadata=&#123;&#125;, <span class="built_in">id</span>=<span class="string">&#x27;f820ff9b-cf06-4c7a-a2e1-12196a6c996b&#x27;</span>), AIMessage(content=<span class="string">&#x27;Of course! How can I assist you today? If you have any questions or need information on a particular topic, feel free to ask.&#x27;</span>, additional_kwargs=&#123;<span class="string">&#x27;refusal&#x27;</span>: <span class="literal">None</span>&#125;, response_metadata=&#123;<span class="string">&#x27;token_usage&#x27;</span>: &#123;<span class="string">&#x27;completion_tokens&#x27;</span>: <span class="number">29</span>, <span class="string">&#x27;prompt_tokens&#x27;</span>: <span class="number">1559</span>, <span class="string">&#x27;total_tokens&#x27;</span>: <span class="number">1588</span>, <span class="string">&#x27;completion_tokens_details&#x27;</span>: <span class="literal">None</span>, <span class="string">&#x27;prompt_tokens_details&#x27;</span>: <span class="literal">None</span>&#125;, <span class="string">&#x27;model_name&#x27;</span>: <span class="string">&#x27;qwen2.5:7b&#x27;</span>, <span class="string">&#x27;system_fingerprint&#x27;</span>: <span class="string">&#x27;fp_ollama&#x27;</span>, <span class="string">&#x27;id&#x27;</span>: <span class="string">&#x27;chatcmpl-353&#x27;</span>, <span class="string">&#x27;service_tier&#x27;</span>: <span class="literal">None</span>, <span class="string">&#x27;finish_reason&#x27;</span>: <span class="string">&#x27;stop&#x27;</span>, <span class="string">&#x27;logprobs&#x27;</span>: <span class="literal">None</span>&#125;, <span class="built_in">id</span>=<span class="string">&#x27;run--2407f4a6-93da-46f9-a1ef-a0db38abcf20-0&#x27;</span>, usage_metadata=&#123;<span class="string">&#x27;input_tokens&#x27;</span>: <span class="number">1559</span>, <span class="string">&#x27;output_tokens&#x27;</span>: <span class="number">29</span>, <span class="string">&#x27;total_tokens&#x27;</span>: <span class="number">1588</span>, <span class="string">&#x27;input_token_details&#x27;</span>: &#123;&#125;, <span class="string">&#x27;output_token_details&#x27;</span>: &#123;&#125;&#125;)]&#125;, <span class="built_in">next</span>=(), config=&#123;<span class="string">&#x27;configurable&#x27;</span>: &#123;<span class="string">&#x27;thread_id&#x27;</span>: <span class="string">&#x27;2&#x27;</span>, <span class="string">&#x27;checkpoint_ns&#x27;</span>: <span class="string">&#x27;&#x27;</span>, <span class="string">&#x27;checkpoint_id&#x27;</span>: <span class="string">&#x27;1f07cbc5-f544-6d92-8001-e1e76d0b63d7&#x27;</span>&#125;&#125;, metadata=&#123;<span class="string">&#x27;source&#x27;</span>: <span class="string">&#x27;loop&#x27;</span>, <span class="string">&#x27;step&#x27;</span>: <span class="number">1</span>, <span class="string">&#x27;parents&#x27;</span>: &#123;&#125;&#125;, created_at=<span class="string">&#x27;2025-08-19T05:21:34.353969+00:00&#x27;</span>, parent_config=&#123;<span class="string">&#x27;configurable&#x27;</span>: &#123;<span class="string">&#x27;thread_id&#x27;</span>: <span class="string">&#x27;2&#x27;</span>, <span class="string">&#x27;checkpoint_ns&#x27;</span>: <span class="string">&#x27;&#x27;</span>, <span class="string">&#x27;checkpoint_id&#x27;</span>: <span class="string">&#x27;1f07cbc5-e589-6aec-8000-7e8fbf548b00&#x27;</span>&#125;&#125;, tasks=(), interrupts=())</span><br><span class="line">snapshot.<span class="built_in">next</span>:  ()</span><br></pre></td></tr></table></figure>



<p>上面的快照包含当前状态值、相应的配置以及<code>next</code>要处理的节点。在我们的例子中，图已达到某个<code>END</code>状态，因此<code>next</code>为空。</p>
<p><strong>恭喜！</strong>借助 LangGraph 的检查点系统，您的聊天机器人现在可以跨会话保持对话状态。这为更自然、更符合情境的交互开辟了激动人心的可能性。LangGraph 的检查点甚至可以处理<strong>任意复杂的图状态</strong>，这比简单的聊天记忆更具表现力和功能强大得多。</p>
<h1 id="完整代码"><a href="#完整代码" class="headerlink" title="完整代码"></a>完整代码</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">from</span> typing <span class="keyword">import</span> Annotated</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> typing_extensions <span class="keyword">import</span> TypedDict</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> langgraph.graph <span class="keyword">import</span> StateGraph, START, END</span><br><span class="line"><span class="keyword">from</span> langgraph.graph.message <span class="keyword">import</span> add_messages</span><br><span class="line"><span class="keyword">from</span> langchain_openai <span class="keyword">import</span> ChatOpenAI</span><br><span class="line"><span class="keyword">from</span> dotenv <span class="keyword">import</span> load_dotenv</span><br><span class="line"><span class="keyword">from</span> langchain_tavily <span class="keyword">import</span> TavilySearch</span><br><span class="line"><span class="keyword">from</span> langgraph.prebuilt <span class="keyword">import</span> ToolNode, tools_condition</span><br><span class="line"><span class="keyword">from</span> langgraph.checkpoint.memory <span class="keyword">import</span> InMemorySaver</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> langchain_core.messages <span class="keyword">import</span> ToolMessage</span><br><span class="line"></span><br><span class="line">load_dotenv()</span><br><span class="line"></span><br><span class="line">memory = InMemorySaver()</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">State</span>(<span class="title class_ inherited__">TypedDict</span>):</span><br><span class="line">    messages: Annotated[<span class="built_in">list</span>, add_messages]</span><br><span class="line"></span><br><span class="line">graph_builder = StateGraph(State)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">llm = ChatOpenAI(</span><br><span class="line">    model=os.getenv(<span class="string">&quot;LLM_MODEL_NAME&quot;</span>),</span><br><span class="line">    api_key=os.getenv(<span class="string">&quot;LLM_API_KEY&quot;</span>),</span><br><span class="line">    base_url=os.getenv(<span class="string">&quot;LLM_BASE_URL&quot;</span>),</span><br><span class="line">    temperature=os.getenv(<span class="string">&quot;LLM_TEMPERATURE&quot;</span>),</span><br><span class="line">    max_tokens=os.getenv(<span class="string">&quot;LLM_MAX_TOKENS&quot;</span>)</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">tool = TavilySearch(max_results=<span class="number">2</span>)</span><br><span class="line">tools = [tool]</span><br><span class="line">llm_with_tools = llm.bind_tools(tools)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">chatbot</span>(<span class="params">state: State</span>):</span><br><span class="line">    <span class="keyword">return</span> &#123;<span class="string">&quot;messages&quot;</span>: [llm_with_tools.invoke(state[<span class="string">&quot;messages&quot;</span>])]&#125;</span><br><span class="line"></span><br><span class="line">graph_builder.add_node(<span class="string">&quot;chatbot&quot;</span>, chatbot)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">tool_node = ToolNode(tools=[tool])</span><br><span class="line">graph_builder.add_node(<span class="string">&quot;tools&quot;</span>, tool_node)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">graph_builder.add_conditional_edges(</span><br><span class="line">    <span class="string">&quot;chatbot&quot;</span>,</span><br><span class="line">    tools_condition,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Any time a tool is called, we return to the chatbot to decide the next step</span></span><br><span class="line">graph_builder.add_edge(<span class="string">&quot;tools&quot;</span>, <span class="string">&quot;chatbot&quot;</span>)</span><br><span class="line">graph_builder.add_edge(START, <span class="string">&quot;chatbot&quot;</span>)</span><br><span class="line">graph = graph_builder.<span class="built_in">compile</span>(checkpointer=memory)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 画图</span></span><br><span class="line">png_bytes = graph.get_graph().draw_mermaid_png()</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&quot;graph.png&quot;</span>, <span class="string">&quot;wb&quot;</span>) <span class="keyword">as</span> f:</span><br><span class="line">    f.write(png_bytes)</span><br><span class="line"></span><br><span class="line"><span class="comment"># import os</span></span><br><span class="line"><span class="comment"># os.system(&quot;open graph.png&quot;)</span></span><br><span class="line"></span><br><span class="line">config = &#123;<span class="string">&quot;configurable&quot;</span>: &#123;<span class="string">&quot;thread_id&quot;</span>: <span class="string">&quot;1&quot;</span>&#125;&#125;</span><br><span class="line"></span><br><span class="line">user_input = <span class="string">&quot;Hi there! My name is Will.&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># The config is the **second positional argument** to stream() or invoke()!</span></span><br><span class="line">events = graph.stream(</span><br><span class="line">    &#123;<span class="string">&quot;messages&quot;</span>: [&#123;<span class="string">&quot;role&quot;</span>: <span class="string">&quot;user&quot;</span>, <span class="string">&quot;content&quot;</span>: user_input&#125;]&#125;,</span><br><span class="line">    config,</span><br><span class="line">    stream_mode=<span class="string">&quot;values&quot;</span>,</span><br><span class="line">)</span><br><span class="line"><span class="keyword">for</span> event <span class="keyword">in</span> events:</span><br><span class="line">    event[<span class="string">&quot;messages&quot;</span>][-<span class="number">1</span>].pretty_print()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">user_input = <span class="string">&quot;Remember my name?&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># The config is the **second positional argument** to stream() or invoke()!</span></span><br><span class="line">events = graph.stream(</span><br><span class="line">    &#123;<span class="string">&quot;messages&quot;</span>: [&#123;<span class="string">&quot;role&quot;</span>: <span class="string">&quot;user&quot;</span>, <span class="string">&quot;content&quot;</span>: user_input&#125;]&#125;,</span><br><span class="line">    config,</span><br><span class="line">    stream_mode=<span class="string">&quot;values&quot;</span>,</span><br><span class="line">)</span><br><span class="line"><span class="keyword">for</span> event <span class="keyword">in</span> events:</span><br><span class="line">    event[<span class="string">&quot;messages&quot;</span>][-<span class="number">1</span>].pretty_print()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">user_input = <span class="string">&quot;Remember my name?&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># The config is the **second positional argument** to stream() or invoke()!</span></span><br><span class="line">events = graph.stream(</span><br><span class="line">    &#123;<span class="string">&quot;messages&quot;</span>: [&#123;<span class="string">&quot;role&quot;</span>: <span class="string">&quot;user&quot;</span>, <span class="string">&quot;content&quot;</span>: user_input&#125;]&#125;,</span><br><span class="line">    &#123;<span class="string">&quot;configurable&quot;</span>: &#123;<span class="string">&quot;thread_id&quot;</span>: <span class="string">&quot;2&quot;</span>&#125;&#125;,</span><br><span class="line">    stream_mode=<span class="string">&quot;values&quot;</span>,</span><br><span class="line">)</span><br><span class="line"><span class="keyword">for</span> event <span class="keyword">in</span> events:</span><br><span class="line">    event[<span class="string">&quot;messages&quot;</span>][-<span class="number">1</span>].pretty_print()</span><br><span class="line"></span><br><span class="line">snapshot = graph.get_state(config)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;snapshot1: &quot;</span>, snapshot)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;snapshot.next: &quot;</span>, snapshot.<span class="built_in">next</span>)</span><br><span class="line"></span><br><span class="line">snapshot = graph.get_state(&#123;<span class="string">&quot;configurable&quot;</span>: &#123;<span class="string">&quot;thread_id&quot;</span>: <span class="string">&quot;2&quot;</span>&#125;&#125;)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;snapshot2: &quot;</span>, snapshot)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;snapshot.next: &quot;</span>, snapshot.<span class="built_in">next</span>)</span><br></pre></td></tr></table></figure>

        </div>
          
        <div class="top-div">
          <ol class="top-box"><li class="top-box-item top-box-level-1"><a class="top-box-link" href="#%E5%88%9B%E5%BB%BAMemorySaver%E6%A3%80%E6%9F%A5%E7%82%B9"><span class="top-box-text">创建MemorySaver检查点</span></a></li><li class="top-box-item top-box-level-1"><a class="top-box-link" href="#%E7%BC%96%E8%AF%91%E5%9B%BE%E8%A1%A8"><span class="top-box-text">编译图表</span></a></li><li class="top-box-item top-box-level-1"><a class="top-box-link" href="#%E4%B8%8E%E4%BD%A0%E7%9A%84%E8%81%8A%E5%A4%A9%E6%9C%BA%E5%99%A8%E4%BA%BA%E4%BA%92%E5%8A%A8"><span class="top-box-text">与你的聊天机器人互动</span></a></li><li class="top-box-item top-box-level-1"><a class="top-box-link" href="#%E6%8F%90%E5%87%BA%E5%90%8E%E7%BB%AD%E9%97%AE%E9%A2%98"><span class="top-box-text">提出后续问题</span></a></li><li class="top-box-item top-box-level-1"><a class="top-box-link" href="#%E6%A3%80%E6%9F%A5%E7%8A%B6%E6%80%81"><span class="top-box-text">检查状态</span></a></li><li class="top-box-item top-box-level-1"><a class="top-box-link" href="#%E5%AE%8C%E6%95%B4%E4%BB%A3%E7%A0%81"><span class="top-box-text">完整代码</span></a></li></ol>
        </div>
          
      </div>
    </div>

    
      <div class="next-post">
        <a class="purple-link" href="/2025/08/llm/langgrapth/langgraph-an-li-ji-qi-ren-tian-jia-gong-ju/">
          <h3 class="post-title">
            
            下一篇：LangGraph 案例：机器人添加工具
          </h3>
        </a>
      </div>
    
  </div>










<footer>
<div class="site-footer">
  <div class="social-container">
    
      
        <a aria-label="跳转至github" href="https://github.com/f-dong" target="_blank">
          <i class="icon icon-github"></i>
        </a>
      
    
      
    
      
    
      
    
      
    
      
    
      
    
      
    
  </div>
  
    Powered by <a href="https://hexo.io/" target="_blank">Hexo</a> <a href="https://github.com/f-dong/hexo-theme-minimalism" target="_blank">Theme</a>
  
  
  
  
  
  
</div>
</footer>


      </div>
    </div>
    
<script id="hexo-configurations"> window.theme_config = {"image":{"lazyload_enable":true,"lazyload_placeholder":null,"photo_zoom":"simple-lightbox"},"search":{"enable":true,"type":"json","placeholder":"输入关键词搜索...","algolia":{"appID":"","apiKey":"","indexName":""}},"language":"zh-Hans"}; window.is_post = true; </script>

<script src="/js/main.js"></script>






  </body>
</html>

